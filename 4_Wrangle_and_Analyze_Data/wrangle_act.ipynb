{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import tweepy\n",
    "import json\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in csv file as a Pandas DataFrame\n",
    "twitter_archive = pd.read_csv('./Data/twitter-archive-enhanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use requests library to download tsv file from a website\n",
    "url=\"https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv\"\n",
    "response = requests.get(url)\n",
    "\n",
    "with open('image_predictions.tsv', 'wb') as file:\n",
    "    file.write(response.content)\n",
    "\n",
    "# Read in tsv file as a Pandas DataFrame    \n",
    "image_predictions = pd.read_csv('image_predictions.tsv', sep='\\t')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Personal API keys, secrets, and tokens have been replaced with placeholders\n",
    "consumer_key = 'MY CONSUMER KEY'\n",
    "consumer_secret = 'MY CONSUMER SECRET'\n",
    "access_token = 'MY ACCESS TOKEN'\n",
    "access_secret = 'MY ACCESS SECRET'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables created for tweepy query\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit = True, wait_on_rate_limit_notify = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loop which will add each available tweet to a new line of tweet_json.txt\n",
    "with open('tweet_json.txt', 'a', encoding='utf8') as f:\n",
    "    for tweet_id in twitter_archive['tweet_id']:\n",
    "        try:\n",
    "            tweet = api.get_status(tweet_id, tweet_mode='extended')\n",
    "            json.dump(tweet._json, f)\n",
    "            f.write('\\n')\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loop to append each tweet into a list\n",
    "tweets_data = []\n",
    "\n",
    "tweet_file = open('tweet_json.txt', \"r\")\n",
    "\n",
    "for line in tweet_file:\n",
    "    try:\n",
    "        tweet = json.loads(line)\n",
    "        tweets_data.append(tweet)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "tweet_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tweet_info DataFrame\n",
    "tweet_info = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add selected variables to tweet_info DataFrame\n",
    "tweet_info['id'] = list(map(lambda tweet: tweet['id'], tweets_data))\n",
    "tweet_info['retweet_count'] = list(map(lambda tweet: tweet['retweet_count'], tweets_data))\n",
    "tweet_info['favorite_count'] = list(map(lambda tweet: tweet['favorite_count'], tweets_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View first 20 rows of twitter_archive DataFrame\n",
    "twitter_archive.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View last 5 rows of twitter_archive DataFrame\n",
    "twitter_archive.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View info of twitter_archive DataFrame\n",
    "twitter_archive.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View descriptive statistics of twitter_archive DataFrame\n",
    "twitter_archive.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View first 5 rows of image_predictions DataFrame\n",
    "image_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View last 5 rows of image_predictions DataFrame\n",
    "image_predictions.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View info of image_predictions DataFrame\n",
    "image_predictions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View descriptive statistics of image_predictions DataFrame\n",
    "image_predictions.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View first 5 rows of tweet_info DataFrame\n",
    "tweet_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Join 'tweet_info' to 'twitter_archive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View last 5 rows of tweet_info DataFrame\n",
    "tweet_info.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View info of tweet_info DataFrame\n",
    "tweet_info.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View descriptive statistics of tweet_info DataFrame\n",
    "tweet_info.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View rows in twitter_archive which contain '&amp;' instead of '&' in 'text' column\n",
    "twitter_archive[twitter_archive.text.str.contains('&amp;')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort values of 'name' column alphabetically - lowercase values appear at the bottom\n",
    "twitter_archive.name.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View number of entries for each source\n",
    "twitter_archive.source.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View rows where the value of 'name' is lowercase - indicates that it is not an actual name\n",
    "twitter_archive.loc[(twitter_archive['name'].str.islower())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View rows where the value of 'name' is lowercase and the word 'named' appears in the 'text' column which indicates \n",
    "# there is an actual dog name in the text\n",
    "twitter_archive.loc[(twitter_archive['name'].str.islower()) & (twitter_archive['text'].str.contains('named'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View rows where the value of 'name' is lowercase and the words 'name is' appears in the 'text' column which indicates \n",
    "# there is an actual dog name in the text\n",
    "twitter_archive.loc[(twitter_archive['name'].str.islower()) & (twitter_archive['text'].str.contains('name is'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View row where dog name is 'O' but we can see in the 'text' column that the dog's name is actually 'O'Malley' \n",
    "twitter_archive[twitter_archive.name == \"O\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#disable warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View rows where text column contains #.#/# indicating a decimal for the rating numerator, \n",
    "# however they do not appear in the 'rating_numerator' column\n",
    "twitter_archive[twitter_archive.text.str.contains(r\"(\\d+\\.\\d*\\/\\d+)\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View row of specific tweet using tweet_id of a tweet that doesn't have a rating \n",
    "twitter_archive[twitter_archive.tweet_id == 810984652412424192]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality\n",
    "\n",
    "- Tweets with no images\n",
    "- Dataset contains retweets\n",
    "- Contents of 'text' cutoff\n",
    "- Incorrect dog names\n",
    "- Missing values in 'name' and dog stages showing as 'None'\n",
    "- Rating numerators with decimals not showing full float\n",
    "- Tweet with more than one #/# sometimes have the first occurence erroneously used for the rating numerators and denominators \n",
    "- Tweet ID# 810984652412424192 doesn't contain a rating\n",
    "- Extra characters after '&'\n",
    "- Sources difficult to read\n",
    "- Erroneous datatypes (timestamp, source, dog stages, tweet_id, in_reply_to_status_id, in_reply_to_user_id)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidiness\n",
    "\n",
    "- Dog \"stage\" variable in four columns: doggo, floofer, pupper, puppo\n",
    "- Join 'tweet_info' and 'image_predictions' to 'twitter_archive'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create copies of original DataFrames to work off of\n",
    "twitter_archive_clean = twitter_archive.copy()\n",
    "image_predictions_clean = image_predictions.copy()\n",
    "tweet_info_clean = tweet_info.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "\n",
    "Create dog stage variable and remove individual dog stage columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'dog_stage' variable which is made by extracting the dog stage variables from the text column when available \n",
    "twitter_archive_clean['dog_stage'] = twitter_archive_clean['text'].str.extract('(puppo|pupper|floofer|doggo)', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variable of columns that are no longer needed and drop them from the DataFrame \n",
    "columns = ['doggo', 'floofer', 'pupper', 'puppo']\n",
    "twitter_archive_clean = twitter_archive_clean.drop(columns, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "\n",
    "Add tweet_info and image_predictions to twitter_archive table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean = pd.merge(left=twitter_archive_clean, right=tweet_info_clean, left_on='tweet_id', right_on='id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean = twitter_archive_clean.merge(image_predictions_clean, on='tweet_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean = twitter_archive_clean.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "\n",
    "Remove rows where there are no images (expanded_urls). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean = twitter_archive_clean.dropna(subset=['expanded_urls'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(twitter_archive_clean['expanded_urls'].isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "\n",
    "Remove retweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows where 'retweeted_status_id' is null to save to twitter_archive_clean\n",
    "twitter_archive_clean = twitter_archive_clean[twitter_archive_clean['retweeted_status_id'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "\n",
    "Remove retweeted columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update columns variable and drop columns related to retweets\n",
    "columns = ['retweeted_status_id', 'retweeted_status_user_id', 'retweeted_status_timestamp']\n",
    "twitter_archive_clean = twitter_archive_clean.drop(columns, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "\n",
    "Display full content of 'text' column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set column width to infinite so entire content of 'text' column is displayed\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "\n",
    "Change incorrect dog names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save locations where 'name' column is lowercase, lowercase and 'text' column contains 'named' and lowercase and 'text'\n",
    "# column contains the words 'name is'\n",
    "named_to_replace = twitter_archive_clean.loc[(twitter_archive_clean['name'].str.islower()) & (twitter_archive_clean['text'].str.contains('named'))]\n",
    "name_is_to_replace = twitter_archive_clean.loc[(twitter_archive_clean['name'].str.islower()) & (twitter_archive_clean['text'].str.contains('name is'))]\n",
    "not_named_to_replace = twitter_archive_clean.loc[(twitter_archive_clean['name'].str.islower())]\n",
    "\n",
    "# Save these locations as lists\n",
    "named_to_replace_list = named_to_replace['text'].tolist()\n",
    "name_is_to_replace_list = name_is_to_replace['text'].tolist()\n",
    "not_named_to_replace_list = not_named_to_replace['text'].tolist()\n",
    "\n",
    "# For loop to iterate through locations where name is lowercase and the words 'named' appear in 'text' and set the 'name' \n",
    "# value to be the word that appears after 'named'\n",
    "for entry in named_to_replace_list:\n",
    "    mask = twitter_archive_clean.text == entry\n",
    "    name_column = 'name'\n",
    "    twitter_archive_clean.loc[mask, name_column] = re.findall(r\"named\\s(\\w+)\", entry)\n",
    "\n",
    "# For loop to iterate through locations where name is lowercase and the words 'name is' appear in 'text' and set the 'name' \n",
    "# value to be the word that appears after 'name is'    \n",
    "for entry in name_is_to_replace_list:\n",
    "    mask = twitter_archive_clean.text == entry\n",
    "    name_column = 'name'\n",
    "    twitter_archive_clean.loc[mask, name_column] = re.findall(r\"name is\\s(\\w+)\", entry)    \n",
    "\n",
    "# For loop to iterate through locations where name is lowercase and replace the name value with the word \"None\"\n",
    "for entry in not_named_to_replace_list:\n",
    "    mask = twitter_archive_clean.text == entry\n",
    "    name_column = 'name'\n",
    "    twitter_archive_clean.loc[mask, name_column] = \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the occurence of \"O\" with \"O'Malley\"\n",
    "twitter_archive_clean.name = twitter_archive_clean.name.replace(\"O\", \"O'Malley\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.name.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.loc[(twitter_archive_clean['name'].str.islower())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean[twitter_archive_clean.name == \"O'Malley\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "\n",
    "Change missing values in 'name' from 'None' to NaN (dog stages already covered)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean['name'] = twitter_archive_clean['name'].replace('None', np.NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "\n",
    "Fix rating numerator and denominators that are not actually ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View all occurences where there are more than one #/# in 'text' column\n",
    "twitter_archive_clean[twitter_archive_clean.text.str.contains( r\"(\\d+\\.?\\d*\\/\\d+\\.?\\d*\\D+\\d+\\.?\\d*\\/\\d+\\.?\\d*)\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the text where the rating numerator and denominators were incorrectly extracted\n",
    "ratings_to_fix = ['After so many requests, this is Bretagne. She was the last surviving 9/11 search dog, and our second ever 14/10. RIP https://t.co/XAVDNDaVgQ', \n",
    " 'Happy 4/20 from the squad! 13/10 for all https://t.co/eV1diwds8a', \n",
    " 'This is Bluebert. He just saw that both #FinalFur match ups are split 50/50. Amazed af. 11/10 https://t.co/Kky1DPG4iq', \n",
    " 'This is Darrel. He just robbed a 7/11 and is in a high speed police chase. Was just spotted by the helicopter 10/10 https://t.co/7EsP8LmSp5',\n",
    " 'This is an Albanian 3 1/2 legged  Episcopalian. Loves well-polished hardwood flooring. Penis on the collar. 9/10 https://t.co/d9NcXFKwLv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the list of ratings to fix and extract the second occurence of #/ to save as the rating numerator. As all the\n",
    "# occurences of the actual ratings in the ratings to fix list have a denominator of 10, we will set that value for each \n",
    "#entry instead of extracting it.\n",
    "for entry in ratings_to_fix:\n",
    "    mask = twitter_archive_clean.text == entry\n",
    "    column_name1 = 'rating_numerator'\n",
    "    column_name2 = 'rating_denominator'\n",
    "    twitter_archive_clean.loc[mask, column_name1] = re.findall(r\"\\d+\\.?\\d*\\/\\d+\\.?\\d*\\D+(\\d+\\.?\\d*)\\/\\d+\\.?\\d*\", entry)\n",
    "    twitter_archive_clean.loc[mask, column_name2] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean[twitter_archive_clean.text.isin(ratings_to_fix)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "\n",
    "Fix rating numerator that have decimals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View tweets with decimals in rating in 'text' column\n",
    "twitter_archive_clean[twitter_archive_clean.text.str.contains(r\"(\\d+\\.\\d*\\/\\d+)\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change datatype of rating_numerator and denominator to float\n",
    "twitter_archive_clean['rating_numerator'] = twitter_archive_clean['rating_numerator'].astype('float')\n",
    "twitter_archive_clean['rating_denominator'] = twitter_archive_clean['rating_denominator'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set correct numerators for specific tweets\n",
    "twitter_archive_clean.loc[(twitter_archive_clean['tweet_id'] == 883482846933004288) & (twitter_archive_clean['rating_numerator'] == 5), ['rating_numerator']] = 13.5\n",
    "twitter_archive_clean.loc[(twitter_archive_clean['tweet_id'] == 786709082849828864) & (twitter_archive_clean['rating_numerator'] == 75), ['rating_numerator']] = 9.75\n",
    "twitter_archive_clean.loc[(twitter_archive_clean['tweet_id'] == 778027034220126208) & (twitter_archive_clean['rating_numerator'] == 27), ['rating_numerator']] = 11.27\n",
    "twitter_archive_clean.loc[(twitter_archive_clean['tweet_id'] == 680494726643068929) & (twitter_archive_clean['rating_numerator'] == 26), ['rating_numerator']] = 11.26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean[twitter_archive_clean.text.str.contains(r\"(\\d+\\.\\d*\\/\\d+)\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "\n",
    "Remove tweet without rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean = twitter_archive_clean[twitter_archive_clean.tweet_id != 810984652412424192]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean[twitter_archive_clean.tweet_id == 810984652412424192]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "\n",
    "Remove extra characters after '&' in twitter_archive_clean['text']."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean['text'] = twitter_archive_clean['text'].str.replace('&amp;', '&')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean[twitter_archive_clean.text.str.contains('&amp;')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "\n",
    "Change sources to more readable categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove url from sources\n",
    "twitter_archive_clean['source'] = twitter_archive_clean['source'].str.replace('<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>', 'Twitter for iPhone')\n",
    "twitter_archive_clean['source'] = twitter_archive_clean['source'].str.replace('<a href=\"http://vine.co\" rel=\"nofollow\">Vine - Make a Scene</a>', 'Vine')\n",
    "twitter_archive_clean['source'] = twitter_archive_clean['source'].str.replace('<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>', 'Twitter Web Client')\n",
    "twitter_archive_clean['source'] = twitter_archive_clean['source'].str.replace('<a href=\"https://about.twitter.com/products/tweetdeck\" rel=\"nofollow\">TweetDeck</a>', 'TweetDeck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change datatype to category\n",
    "twitter_archive_clean['source'] = twitter_archive_clean['source'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.source.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "\n",
    "Change datatypes of timestamp to datetime, dog_stage to categorical, and tweet_id, in_reply_to_status_id, and in_reply_to_user_id to strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean['dog_stage'] = twitter_archive_clean['dog_stage'].astype('category')\n",
    "twitter_archive_clean['timestamp'] = pd.to_datetime(twitter_archive_clean['timestamp'])\n",
    "twitter_archive_clean['tweet_id'] = twitter_archive_clean['tweet_id'].astype('str')\n",
    "twitter_archive_clean['in_reply_to_status_id'] = twitter_archive_clean['in_reply_to_status_id'].astype('str')\n",
    "twitter_archive_clean['in_reply_to_user_id'] = twitter_archive_clean['in_reply_to_user_id'].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save clean DataFrame to csv file\n",
    "twitter_archive_clean.to_csv('twitter_archive_master.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create copy of twitter_archive_clean to work off of using only my variables of interest\n",
    "time_df = twitter_archive_clean[['timestamp', 'retweet_count', 'favorite_count', 'rating_numerator', 'rating_denominator']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the index to be the timestamp so time is displayed properly in plots\n",
    "time_df.set_index('timestamp', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rating_ration variable by dividing the rating numerator by the deonominator to normalize scores which are not \n",
    "# out of 10\n",
    "time_df['rating_ratio'] = time_df['rating_numerator']/time_df['rating_denominator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df['retweet_count'].plot(color = 'red', label='Retweets')\n",
    "time_df['favorite_count'].plot(color = 'blue', label='Favorites')\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Tweet timestamp')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Retweets and favorites over time')\n",
    "plt.savefig('retweets_favorites.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df['rating_ratio'].plot()\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Ratio')\n",
    "plt.title('Rating ratio over time')\n",
    "plt.savefig('ratio.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Limit y axis to zoom in on data and ignore outliers\n",
    "time_df['rating_ratio'].plot()\n",
    "plt.ylim(-1, 3)\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Ratio')\n",
    "plt.title('Rating ratio over time')\n",
    "plt.savefig('ratio_zoom.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
